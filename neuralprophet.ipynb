{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a16dc59d",
   "metadata": {},
   "source": [
    "# Advanced Time Series Forecasting — NeuralProphet + Optuna\n",
    "\n",
    "This notebook implements the project **exactly according to the project conditions** you provided:\n",
    "- Use **NeuralProphet** as the forecasting model.\n",
    "- Perform **blocked cross-validation** suitable for time series.\n",
    "- Use **Optuna** for hyperparameter optimization.\n",
    "- Provide **production-ready** code, detailed markdown explanations, and final deliverables (top-5 hyperparameters, holdout evaluation, plots, and CSV export).\n",
    "\n",
    "This notebook has been adapted to match your project submission format and documentation.  \n",
    "(Referenced project README uploaded by you: `/mnt/data/README.md`.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da494d7",
   "metadata": {},
   "source": [
    "**Local README path:** `/mnt/data/README.md`\n",
    "\n",
    "Use this as the canonical project README for final submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d793bd",
   "metadata": {},
   "source": [
    "## 1) Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7a739e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "neuralprophet_optuna_project.py\n",
    "\n",
    "Advanced Time Series Forecasting project:\n",
    "- Generates a synthetic daily time series (4 years)\n",
    "- Implements NeuralProphet baseline\n",
    "- Uses Optuna for hyperparameter optimization with blocked CV\n",
    "- Evaluates with RMSE and MAE and outputs top-5 hyperparameter configs\n",
    "\n",
    "Requirements (install before running):\n",
    "    pip install neuralprophet optuna pandas numpy matplotlib scikit-learn\n",
    "\n",
    "Note: NeuralProphet sometimes requires PyTorch. Ensure your environment supports it:\n",
    "    pip install torch --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "Usage:\n",
    "    python neuralprophet_optuna_project.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import optuna\n",
    "\n",
    "# Attempt to import NeuralProphet; if missing, instruct the user\n",
    "try:\n",
    "    from neuralprophet import NeuralProphet, set_log_level\n",
    "except Exception as ex:\n",
    "    raise ImportError(\n",
    "        \"NeuralProphet is not installed or failed to import. \"\n",
    "        \"Install with `pip install neuralprophet` and ensure PyTorch is available.\"\n",
    "    ) from ex\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "set_log_level(\"ERROR\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c02bd",
   "metadata": {},
   "source": [
    "## 2) Synthetic dataset generation\n",
    "Generates a 4+ year daily timeseries with seasonality, holidays, changepoints, and noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42398e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_daily_series(\n",
    "    start_date: str = \"2017-01-01\",\n",
    "    end_date: str = \"2021-12-31\",\n",
    "    seed: int = 42,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a synthetic daily time series with:\n",
    "      - yearly seasonality\n",
    "      - weekly seasonality\n",
    "      - synthetic holiday effects\n",
    "      - multiple changepoints (abrupt level shifts)\n",
    "      - Gaussian noise\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns ['ds','y'] where 'ds' is datetime and 'y' is observed value.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "    n = len(dates)\n",
    "    t = np.arange(n) / 365.0  # time in years\n",
    "\n",
    "    # Yearly seasonal component (smooth)\n",
    "    yearly = 10.0 * np.sin(2 * math.pi * t)  # amplitude 10\n",
    "\n",
    "    # Weekly seasonality (weekday effects)\n",
    "    weekday = np.array([0.0 if d.weekday() < 5 else 3.0 for d in dates])\n",
    "\n",
    "    # Trend (linear + changepoints)\n",
    "    trend = 0.5 * t  # gentle upward trend\n",
    "    # Add changepoints: at specific indices add shifts\n",
    "    changepoints = [\n",
    "        int(0.6 * n),\n",
    "        int(0.35 * n),\n",
    "    ]\n",
    "    trend_shift = np.zeros(n)\n",
    "    for cp in changepoints:\n",
    "        trend_shift[cp:] += rng.normal(5.0, 1.0)  # abrupt shift\n",
    "\n",
    "    # Synthetic holiday effect: create some date list and add pulses\n",
    "    holidays = [\n",
    "        pd.Timestamp(\"2017-12-25\"),\n",
    "        pd.Timestamp(\"2018-12-25\"),\n",
    "        pd.Timestamp(\"2019-12-25\"),\n",
    "        pd.Timestamp(\"2020-12-25\"),\n",
    "        pd.Timestamp(\"2021-12-25\"),\n",
    "    ]\n",
    "    holiday_effect = np.zeros(n)\n",
    "    for i, d in enumerate(dates):\n",
    "        if d in holidays:\n",
    "            holiday_effect[i] += 8.0 + rng.normal(0.0, 1.0)\n",
    "\n",
    "    # Noise\n",
    "    noise = rng.normal(0.0, 2.5, size=n)\n",
    "\n",
    "    y = 20.0 + 3.0 * trend + trend_shift + yearly + weekday + holiday_effect + noise\n",
    "\n",
    "    df = pd.DataFrame({\"ds\": dates, \"y\": y})\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4390a966",
   "metadata": {},
   "source": [
    "## 3) Blocked cross-validation helper\n",
    "Create time-based folds with no leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blocked_time_series_folds(\n",
    "    df: pd.DataFrame, n_folds: int = 3, test_size_days: int = 90\n",
    ") -> List[Tuple[pd.DataFrame, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Create blocked (time-based) cross-validation folds.\n",
    "    Each fold uses earlier data for train and the next contiguous block for validation.\n",
    "    The final held-out test block is returned for final evaluation separately.\n",
    "\n",
    "    Returns:\n",
    "        list of (train_df, val_df)\n",
    "    \"\"\"\n",
    "    dates = df[\"ds\"].sort_values().unique()\n",
    "    total_days = len(dates)\n",
    "    fold_size = (total_days - test_size_days) // (n_folds + 1)\n",
    "\n",
    "    folds = []\n",
    "    for i in range(n_folds):\n",
    "        train_end_idx = (i + 1) * fold_size\n",
    "        val_start_idx = train_end_idx\n",
    "        val_end_idx = val_start_idx + fold_size\n",
    "        train_dates = dates[:train_end_idx]\n",
    "        val_dates = dates[val_start_idx:val_end_idx]\n",
    "        train_df = df[df[\"ds\"].isin(train_dates)].reset_index(drop=True)\n",
    "        val_df = df[df[\"ds\"].isin(val_dates)].reset_index(drop=True)\n",
    "        folds.append((train_df, val_df))\n",
    "    return folds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ed4a7",
   "metadata": {},
   "source": [
    "## 4) Training & evaluation function\n",
    "Train NeuralProphet using given hyperparameters and evaluate RMSE/MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90701d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_np(\n",
    "    train_df: pd.DataFrame,\n",
    "    val_df: pd.DataFrame,\n",
    "    params: Dict,\n",
    "    verbose: bool = False,\n",
    ") -> Tuple[float, float, NeuralProphet]:\n",
    "    \"\"\"\n",
    "    Train NeuralProphet on train_df using params and evaluate on val_df.\n",
    "    Returns (rmse, mae, model)\n",
    "    \"\"\"\n",
    "    # Setup model configuration from params\n",
    "    model = NeuralProphet(\n",
    "        n_changepoints=int(params.get(\"n_changepoints\", 10)),\n",
    "        changepoints_range=params.get(\"changepoints_range\", 0.8),\n",
    "        yearly_seasonality=params.get(\"yearly_seasonality\", True),\n",
    "        weekly_seasonality=params.get(\"weekly_seasonality\", True),\n",
    "        daily_seasonality=False,\n",
    "        seasonality_mode=params.get(\"seasonality_mode\", \"additive\"),\n",
    "        learning_rate=params.get(\"learning_rate\", 1.0),\n",
    "        epochs=int(params.get(\"epochs\", 50)),\n",
    "        ar_sparsity=params.get(\"ar_sparsity\", 0.0),\n",
    "        loss_func=params.get(\"loss_func\", \"MSE\"),\n",
    "    )\n",
    "\n",
    "    # Fit model\n",
    "    model.fit(train_df, freq=\"D\", progress=None)\n",
    "\n",
    "    # Make predictions on validation\n",
    "    future = val_df[[\"ds\"]].copy()\n",
    "    forecast = model.predict(future)\n",
    "    y_true = val_df[\"y\"].values\n",
    "    y_pred = forecast[\"yhat1\"].values\n",
    "\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    if verbose:\n",
    "        print(f\"RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "    return rmse, mae, model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a57aec",
   "metadata": {},
   "source": [
    "## 5) Baseline evaluation and Optuna optimization\n",
    "This cell defines the baseline parameters and the Optuna study (objective)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fa087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_and_optimize(\n",
    "    df: pd.DataFrame,\n",
    "    n_folds: int = 3,\n",
    "    test_size_days: int = 90,\n",
    "    n_trials: int = 40,\n",
    "    seed: int = 42,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Run baseline evaluation and Optuna optimization. Returns dictionary of results including top trials.\n",
    "    \"\"\"\n",
    "    # Reserve final holdout test (last test_size_days)\n",
    "    df_sorted = df.sort_values(\"ds\").reset_index(drop=True)\n",
    "    holdout = df_sorted.iloc[-test_size_days:].reset_index(drop=True)\n",
    "    in_sample = df_sorted.iloc[: -test_size_days].reset_index(drop=True)\n",
    "\n",
    "    # Baseline: default NeuralProphet with modest epochs\n",
    "    baseline_params = {\n",
    "        \"n_changepoints\": 10,\n",
    "        \"changepoints_range\": 0.8,\n",
    "        \"seasonality_mode\": \"additive\",\n",
    "        \"learning_rate\": 1.0,\n",
    "        \"epochs\": 50,\n",
    "        \"ar_sparsity\": 0.0,\n",
    "        \"loss_func\": \"MSE\",\n",
    "        \"yearly_seasonality\": True,\n",
    "        \"weekly_seasonality\": True,\n",
    "    }\n",
    "\n",
    "    # Cross-validation folds\n",
    "    folds = blocked_time_series_folds(in_sample, n_folds=n_folds, test_size_days=test_size_days)\n",
    "\n",
    "    # Baseline CV\n",
    "    baseline_rmses = []\n",
    "    baseline_maes = []\n",
    "    for (tr, va) in folds:\n",
    "        rmse, mae, _ = train_evaluate_np(tr, va, baseline_params)\n",
    "        baseline_rmses.append(rmse)\n",
    "        baseline_maes.append(mae)\n",
    "    baseline_rmse_mean = float(np.mean(baseline_rmses))\n",
    "    baseline_mae_mean = float(np.mean(baseline_maes))\n",
    "\n",
    "    print(f\"Baseline CV RMSE: {baseline_rmse_mean:.4f}, MAE: {baseline_mae_mean:.4f}\")\n",
    "\n",
    "    # Optuna study\n",
    "    def objective(trial: optuna.trial.Trial) -> float:\n",
    "        params = {\n",
    "            \"n_changepoints\": trial.suggest_int(\"n_changepoints\", 5, 50),\n",
    "            \"changepoints_range\": trial.suggest_float(\"changepoints_range\", 0.5, 0.95),\n",
    "            \"seasonality_mode\": trial.suggest_categorical(\"seasonality_mode\", [\"additive\", \"multiplicative\"]),\n",
    "            \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-4, 1.0),\n",
    "            \"epochs\": trial.suggest_int(\"epochs\", 30, 200),\n",
    "            \"ar_sparsity\": trial.suggest_float(\"ar_sparsity\", 0.0, 0.9),\n",
    "            \"loss_func\": \"MSE\",\n",
    "            \"yearly_seasonality\": True,\n",
    "            \"weekly_seasonality\": True,\n",
    "        }\n",
    "\n",
    "        # Evaluate across folds and return mean RMSE\n",
    "        cv_rmse = []\n",
    "        for (tr, va) in folds:\n",
    "            try:\n",
    "                rmse, _, _ = train_evaluate_np(tr, va, params)\n",
    "            except Exception as e:\n",
    "                # If training fails, return large penalty\n",
    "                print(\"Trial training failed:\", e)\n",
    "                return 1e6\n",
    "            cv_rmse.append(rmse)\n",
    "        return float(np.mean(cv_rmse))\n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "\n",
    "    print(\"Optimization completed. Best trial:\")\n",
    "    print(study.best_trial.params)\n",
    "\n",
    "    # Evaluate top 5 trials on holdout test set and record metrics\n",
    "    trials_df = study.trials_dataframe()\n",
    "    # Sort by value (mean CV RMSE)\n",
    "    best_trials = sorted(study.trials, key=lambda t: t.value)[:5]\n",
    "\n",
    "    top5_results = []\n",
    "    for t in best_trials:\n",
    "        params = dict(t.params)\n",
    "        # add defaults for keys not present\n",
    "        params.setdefault(\"loss_func\", \"MSE\")\n",
    "        params[\"yearly_seasonality\"] = True\n",
    "        params[\"weekly_seasonality\"] = True\n",
    "        params[\"epochs\"] = int(params.get(\"epochs\", 50))\n",
    "        # retrain on entire in-sample (i.e., before holdout)\n",
    "        rmse, mae, model = train_evaluate_np(in_sample, holdout, params)\n",
    "        top5_results.append(\n",
    "            {\n",
    "                \"trial\": t.number,\n",
    "                \"value_cv_rmse\": float(t.value),\n",
    "                \"holdout_rmse\": float(rmse),\n",
    "                \"holdout_mae\": float(mae),\n",
    "                \"params\": params,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    results = {\n",
    "        \"baseline\": {\n",
    "            \"cv_rmse\": baseline_rmse_mean,\n",
    "            \"cv_mae\": baseline_mae_mean,\n",
    "            \"params\": baseline_params,\n",
    "        },\n",
    "        \"study\": study,\n",
    "        \"top5\": top5_results,\n",
    "        \"holdout\": {\"df\": holdout},\n",
    "    }\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b797f2",
   "metadata": {},
   "source": [
    "## 6) Helpers to save results and plot forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514945d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_top5_to_csv(top5: List[Dict], csv_path: str = \"top5_hyperparams.csv\") -> None:\n",
    "    \"\"\"\n",
    "    Save the top5 results to a CSV file (one json-encoded params cell).\n",
    "    \"\"\"\n",
    "    with open(csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"trial\", \"cv_rmse\", \"holdout_rmse\", \"holdout_mae\", \"params_json\"])\n",
    "        for r in top5:\n",
    "            writer.writerow(\n",
    "                [r[\"trial\"], r[\"value_cv_rmse\"], r[\"holdout_rmse\"], r[\"holdout_mae\"], json.dumps(r[\"params\"])]\n",
    "            )\n",
    "    print(f\"Top 5 hyperparameter results saved to {csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast_comparison(model: NeuralProphet, df_true: pd.DataFrame, save_path: str = \"forecast.png\") -> None:\n",
    "    \"\"\"\n",
    "    Generate a comparison plot of the model forecast vs actual for df_true (must include 'ds').\n",
    "    \"\"\"\n",
    "    future = df_true[[\"ds\"]].copy()\n",
    "    forecast = model.predict(future)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(df_true[\"ds\"], df_true[\"y\"], label=\"actual\")\n",
    "    plt.plot(df_true[\"ds\"], forecast[\"yhat1\"], label=\"forecast\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(\"Forecast vs Actual (holdout)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    print(f\"Forecast plot saved to {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd86818",
   "metadata": {},
   "source": [
    "## 7) Run the full pipeline\n",
    "\n",
    "**Notes before running**\n",
    "- Ensure `neuralprophet`, `optuna`, `pandas`, `numpy`, `matplotlib`, `scikit-learn`, and `torch` are installed.\n",
    "- For a quick demo use `n_trials=8`. For submission-quality runs, set `n_trials=50` or more.\n",
    "- The script will:\n",
    "  - generate the synthetic dataset,\n",
    "  - run baseline CV,\n",
    "  - run Optuna optimization,\n",
    "  - save `top5_hyperparams.csv`,\n",
    "  - save `best_model_forecast.png`.\n",
    "\n",
    "Execute the cell below to run the experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the pipeline (demo)\n",
    "df = generate_synthetic_daily_series(start_date=\"2017-01-01\", end_date=\"2021-12-31\", seed=123)\n",
    "print(f\"Dataset rows: {len(df)}; range: {df['ds'].min()} to {df['ds'].max()}\")\n",
    "\n",
    "results = baseline_and_optimize(df, n_folds=3, test_size_days=90, n_trials=8, seed=42)\n",
    "\n",
    "# Print summary\n",
    "print(\"Baseline CV RMSE: {:.4f}, MAE: {:.4f}\".format(results[\"baseline\"][\"cv_rmse\"], results[\"baseline\"][\"cv_mae\"]))\n",
    "print(\"\\nTop 5 trials (summary):\")\n",
    "for r in results[\"top5\"]:\n",
    "    print(f\"Trial {r['trial']}: CV_RMSE={r['value_cv_rmse']:.4f}, Holdout_RMSE={r['holdout_rmse']:.4f}, Holdout_MAE={r['holdout_mae']:.4f}\")\n",
    "    print(\"Params:\", r[\"params\"])\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Save and show files location\n",
    "save_top5_to_csv(results[\"top5\"], csv_path=\"top5_hyperparams.csv\")\n",
    "\n",
    "# Retrain best on in-sample and plot vs holdout\n",
    "best_params = results[\"top5\"][0][\"params\"]\n",
    "_, _, best_model = train_evaluate_np(df.iloc[:-90].reset_index(drop=True), results[\"holdout\"][\"df\"], best_params)\n",
    "try:\n",
    "    plot_forecast_comparison(best_model, results[\"holdout\"][\"df\"], save_path=\"best_model_forecast.png\")\n",
    "except Exception as e:\n",
    "    print(\"Plotting failed:\", e)\n",
    "\n",
    "print(\"Artifacts saved: top5_hyperparams.csv, best_model_forecast.png (if plotting succeeded).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9102a44f",
   "metadata": {},
   "source": [
    "**Project README you provided:**\n",
    "\n",
    "See the uploaded README for project specs: `/mnt/data/README.md`\n",
    "\n",
    "Citation: fileciteturn0file0"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
